# ğŸ¤– RAG Chatbot â€“ Ollama (Local)  
Chatbot RAG (Retrieval-Augmented Generation) complet, puissant et 100% local.  
Construit avec **Streamlit**, **LangChain**, **ChromaDB**, et **Ollama**, il permet dâ€™interroger intelligemment vos documents (PDF, TXT, DOCX, MD) grÃ¢ce Ã  un pipeline dâ€™indexation + LLM local optimisÃ©.

---

# âœ¨ FonctionnalitÃ©s

### ğŸ” Recherche intelligente (RAG)
- Extraction + dÃ©coupage automatique des documents  
- Embeddings via **nomic-embed-text** (Ollama)  
- Indexation vectorielle avec **ChromaDB**  
- RAG complet : *retrieval â†’ contexte â†’ LLM gÃ©nÃ©ratif*

### ğŸ¤– Interface Chatbot AvancÃ©e
- Streaming du texte (effet Ã©criture)  
- Bulle â€œLamBot rÃ©flÃ©chitâ€¦â€ animÃ©e  
- Mode sombre entiÃ¨rement custom  
- Historique enrichi (date + heure)  
- Messages rÃ©cents en haut  
- Raccourcis ergonomiques

### ğŸ—‚ï¸ SystÃ¨me de Sessions (multi-conversations)
- CrÃ©er des conversations  
- Renommer  
- Supprimer  
- Navigation entre sessions  
- Sauvegarde automatique dans `chat_sessions.json`

### ğŸ“Œ Outils professionnels
- Ã‰pinglage de rÃ©ponses importantes  
- RÃ©sumÃ© automatique de conversation via LLM  
- Export Markdown (.md)  
- Export JSON (rÃ©-importable)  
- Import de conversations  
- Suppression dernier Ã©change ou reset complet  

### ğŸ“‚ Gestion des documents
- Upload PDF / TXT / MD / DOCX  
- Indexation automatique  
- Reconstruction manuelle si nÃ©cessaire  
- Viewer PDF intÃ©grÃ©  
- Localisation : dossier `./data`

---

# ğŸ“¦ Installation

## 1ï¸âƒ£ Cloner le dÃ©pÃ´t

```bash
git clone https://github.com/laminefaye69100/rag-chatbot.git
cd rag-chatbot
```

## 2ï¸âƒ£ CrÃ©er un environnement virtuel

### Linux / macOS
```bash
python3 -m venv .venv
source .venv/bin/activate
```

### Windows
```bash
python -m venv .venv
.venv\Scripts\activate
```

## 3ï¸âƒ£ Installer les dÃ©pendances
```bash
pip install -r requirements.txt
```

## 4ï¸âƒ£ Installer Ollama + modÃ¨les nÃ©cessaires
Installer Ollama :  
ğŸ‘‰ https://ollama.com

TÃ©lÃ©charger les modÃ¨les :

```bash
ollama pull llama3.2:1b
ollama pull phi3:mini
ollama pull nomic-embed-text
```

## 5ï¸âƒ£ Lancer Ollama
```bash
ollama serve
```

---

# ğŸ§  Indexation de documents

Place tes fichiers dans :

```
./data/
```

Puis gÃ©nÃ¨re lâ€™index :

```bash
python build_index.py
```

Ou laisse lâ€™application indexer automatiquement lorsque tu uploades un document.

---

# ğŸš€ Lancer lâ€™application Streamlit

```bash
streamlit run app.py
```

Application disponible sur :  
ğŸ‘‰ **http://localhost:8501/**

---

# ğŸ“– Guide dâ€™utilisation

### ğŸ—‚ï¸ Gestion des conversations
- Changer de conversation  
- CrÃ©er une nouvelle  
- Renommer  
- Supprimer  
- Historique sauvegardÃ© automatiquement  

### âœï¸ Utiliser le chatbot
- Ã‰crire une question  
- Recevoir une rÃ©ponse basÃ©e sur vos documents  
- Visualisation en streaming  

### ğŸ“Œ FonctionnalitÃ©s avancÃ©es
- Ã‰pingler une rÃ©ponse informative  
- Export Markdown  
- Export JSON  
- Import JSON en nouvelle conversation  
- RÃ©sumÃ© automatique structurÃ©  

### ğŸ“„ Lecture des PDF
- SÃ©lectionner un PDF dans la liste  
- Affichage intÃ©grÃ© via iframe  
- Lisible immÃ©diatement dans le navigateur  

---

# ğŸ“Š Architecture du projet

```
rag-chatbot/
â”‚â”€â”€ app.py                 # Interface Streamlit (chat, sessions, outilsâ€¦)
â”‚â”€â”€ rag_pipeline.py        # Pipeline RAG (retriever + prompt + LLM)
â”‚â”€â”€ build_index.py         # Construction / actualisation de lâ€™index Chroma
â”‚â”€â”€ load_documents.py      # Chargement + dÃ©coupage PDF/TXT/MD/DOCX
â”‚â”€â”€ requirements.txt       # DÃ©pendances
â”‚â”€â”€ chat_sessions.json     # Sauvegarde multi-conversations
â”‚â”€â”€ chroma/                # Base vectorielle persistante
â”‚â”€â”€ data/                  # Documents utilisateur
â”‚â”€â”€ README.md              # Documentation
```

---

# ğŸ”§ Technologies utilisÃ©es

| Composant | Description |
|----------|-------------|
| **Streamlit** | Interface web simple et performante |
| **LangChain** | Orchestration du RAG |
| **ChromaDB** | Stockage vectoriel des embeddings |
| **Ollama** | ExÃ©cution locale des modÃ¨les |
| **llama3.2:1b** | LLM local pour la gÃ©nÃ©ration |
| **phi3:mini** | ModÃ¨le fallback |
| **nomic-embed-text** | Embeddings performants |

---

# ğŸ§ª Tester le pipeline RAG

Quelques questions possibles :

- *"Donne-moi un rÃ©sumÃ© du document X ?"*
- *"Quels sont les points clÃ©s du chapitre 2 ?"*
- *"Explique-moi ce passage prÃ©sent dans le PDF."*  
- *"Quelle rÃ©ponse a Ã©tÃ© donnÃ©e dans la conversation prÃ©cÃ©dente ?"*

---

# ğŸ‘¨â€ğŸ’» Auteur

**Amadou Lamine Faye**  
Master 2 â€“ Intelligence Artificielle  
UniversitÃ© Lyon 1  

GitHub : https://github.com/laminefaye69100

---

# ğŸ“œ Licence

Projet disponible uniquement pour usage personnel et acadÃ©mique.  
Revente ou redistribution interdite sans autorisation.

---

Si tu veux une version encore plus professionnelle (badges, images, schÃ©mas UML du pipeline, GIF du chatbot, etc.), je peux la gÃ©nÃ©rer ! ğŸš€


---
## ğŸ“ Notes supplÃ©mentaires

- Le RAG utilise **Ollama (CPU/GPU)** â†’ fonctionne totalement **horsâ€‘ligne**
- Lâ€™index est **persistant** â†’ redÃ©marrage possible sans reconstruction
- Aucun cloud â†’ **donnÃ©es 100% privÃ©es**
- Compatible **Linux / macOS / Windows**
